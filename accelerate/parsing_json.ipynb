{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)  # Display all rows\n",
    "pd.set_option(\"display.max_columns\", None)  # Display all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>cpu_util</th>\n",
       "      <th>cpu_mem</th>\n",
       "      <th>gpu_0_util</th>\n",
       "      <th>gpu_1_util</th>\n",
       "      <th>gpu_0_mem</th>\n",
       "      <th>gpu_1_mem</th>\n",
       "      <th>gpu_0_power</th>\n",
       "      <th>gpu_1_power</th>\n",
       "      <th>gpu_0_temp</th>\n",
       "      <th>gpu_1_temp</th>\n",
       "      <th>disk_read</th>\n",
       "      <th>disk_write</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-20 14:57:23.567798</td>\n",
       "      <td>6.059375</td>\n",
       "      <td>18814763008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.556</td>\n",
       "      <td>9.166</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>235110.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-20 14:57:28.572094</td>\n",
       "      <td>6.265625</td>\n",
       "      <td>18814763008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.556</td>\n",
       "      <td>9.166</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>235110.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-20 14:57:33.577217</td>\n",
       "      <td>7.412500</td>\n",
       "      <td>21593022464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.556</td>\n",
       "      <td>9.166</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5719654.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-20 14:57:38.734310</td>\n",
       "      <td>6.018750</td>\n",
       "      <td>23755390976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.556</td>\n",
       "      <td>9.166</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>87654.4</td>\n",
       "      <td>344883.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-20 14:57:43.744203</td>\n",
       "      <td>6.018750</td>\n",
       "      <td>23755390976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.556</td>\n",
       "      <td>9.166</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>157286.4</td>\n",
       "      <td>472678.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-10-20 14:57:48.748600</td>\n",
       "      <td>6.375000</td>\n",
       "      <td>23941623808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.556</td>\n",
       "      <td>9.166</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>157286.4</td>\n",
       "      <td>472678.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-10-20 14:57:53.753641</td>\n",
       "      <td>5.846875</td>\n",
       "      <td>23979106304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.361</td>\n",
       "      <td>9.747</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406323.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-10-20 14:57:58.758627</td>\n",
       "      <td>6.234375</td>\n",
       "      <td>23980040192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.361</td>\n",
       "      <td>9.747</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>367820.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-10-20 14:58:03.763678</td>\n",
       "      <td>6.731250</td>\n",
       "      <td>23938371584</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.361</td>\n",
       "      <td>9.747</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>266240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-10-20 14:58:08.885687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23933779968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.361</td>\n",
       "      <td>9.747</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-10-20 14:58:17.599268</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>21098151936</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.361</td>\n",
       "      <td>9.747</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168996044.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          time  cpu_util      cpu_mem  gpu_0_util  gpu_1_util  \\\n",
       "0   2023-10-20 14:57:23.567798  6.059375  18814763008           0           0   \n",
       "1   2023-10-20 14:57:28.572094  6.265625  18814763008           0           0   \n",
       "2   2023-10-20 14:57:33.577217  7.412500  21593022464           0           0   \n",
       "3   2023-10-20 14:57:38.734310  6.018750  23755390976           0           0   \n",
       "4   2023-10-20 14:57:43.744203  6.018750  23755390976           0           0   \n",
       "5   2023-10-20 14:57:48.748600  6.375000  23941623808           0           0   \n",
       "6   2023-10-20 14:57:53.753641  5.846875  23979106304           0           0   \n",
       "7   2023-10-20 14:57:58.758627  6.234375  23980040192           0           0   \n",
       "8   2023-10-20 14:58:03.763678  6.731250  23938371584           0           0   \n",
       "9   2023-10-20 14:58:08.885687       NaN  23933779968           0           0   \n",
       "10  2023-10-20 14:58:17.599268  5.125000  21098151936           0           0   \n",
       "\n",
       "    gpu_0_mem  gpu_1_mem  gpu_0_power  gpu_1_power  gpu_0_temp  gpu_1_temp  \\\n",
       "0           0          0        9.556        9.166          31          27   \n",
       "1           0          0        9.556        9.166          31          27   \n",
       "2           0          0        9.556        9.166          31          27   \n",
       "3           0          0        9.556        9.166          31          27   \n",
       "4           0          0        9.556        9.166          31          27   \n",
       "5           0          0        9.556        9.166          31          27   \n",
       "6           0          0        9.361        9.747          30          27   \n",
       "7           0          0        9.361        9.747          30          27   \n",
       "8           0          0        9.361        9.747          30          27   \n",
       "9           0          0        9.361        9.747          30          27   \n",
       "10          0          0        9.361        9.747          30          27   \n",
       "\n",
       "    disk_read   disk_write  \n",
       "0         0.0     235110.4  \n",
       "1         0.0     235110.4  \n",
       "2         0.0    5719654.4  \n",
       "3     87654.4     344883.2  \n",
       "4    157286.4     472678.4  \n",
       "5    157286.4     472678.4  \n",
       "6         0.0     406323.2  \n",
       "7         0.0     367820.8  \n",
       "8         0.0     266240.0  \n",
       "9         NaN          NaN  \n",
       "10        0.0  168996044.8  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./output/bloom-560m/np2-bs8/metrics.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cpu_util] min: 5.12, max: 7.41, avg: 6.21\n",
      "[cpu_mem] min: 18814763008.00, max: 23980040192.00, avg: 22509491293.09\n",
      "[gpu_0_util] min: 0.00, max: 0.00, avg: 0.00\n",
      "[gpu_1_util] min: 0.00, max: 0.00, avg: 0.00\n",
      "[gpu_0_mem] min: 0.00, max: 0.00, avg: 0.00\n",
      "[gpu_1_mem] min: 0.00, max: 0.00, avg: 0.00\n",
      "[gpu_0_power] min: 9.36, max: 9.56, avg: 9.47\n",
      "[gpu_1_power] min: 9.17, max: 9.75, avg: 9.43\n",
      "[gpu_0_temp] min: 30.00, max: 31.00, avg: 30.55\n",
      "[gpu_1_temp] min: 27.00, max: 27.00, avg: 27.00\n",
      "[disk_read] min: 0.00, max: 157286.40, avg: 40222.72\n",
      "[disk_write] min: 235110.40, max: 168996044.80, avg: 17751654.40\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    if not col == \"time\":\n",
    "        print(f\"[{col}] min: {df[col].min():.2f}, max: {df[col].max():.2f}, avg: {df[col].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = glob(\"./logs/bigscience/bloom-1b1/**/*.json\", recursive=True)\n",
    "total_durs = {}\n",
    "\n",
    "for trace in traces:\n",
    "    with open(trace) as f:\n",
    "        json_dict = json.load(f)\n",
    "\n",
    "    total_dur = {}\n",
    "\n",
    "    for event in json_dict[\"traceEvents\"]:\n",
    "        if not \"dur\" in event:\n",
    "            continue\n",
    "\n",
    "        cat = event[\"cat\"]\n",
    "        dur = event[\"dur\"]\n",
    "        name = event[\"name\"]\n",
    "\n",
    "        if not dur:\n",
    "            continue\n",
    "\n",
    "        if not cat in total_dur:\n",
    "            total_dur[cat] = defaultdict(int)\n",
    "\n",
    "        total_dur[cat][name] += dur\n",
    "\n",
    "    rows = []\n",
    "    for cat, sub_dict in total_dur.items():\n",
    "        for name, dur in sub_dict.items():\n",
    "            rows.append({\n",
    "                \"cat\": cat,\n",
    "                \"name\": name,\n",
    "                \"dur\": dur,\n",
    "            })\n",
    "\n",
    "    total_durs[trace.split(\"/\")[-2]] = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np8-bs32\n",
      "ManipulateTensor (length: 226 --> 143)\n",
      "CalculateGradient (length: 143 --> 120)\n",
      "Backward (length: 120 --> 97)\n",
      "\n",
      "np1-bs32\n",
      "ManipulateTensor (length: 216 --> 133)\n",
      "CalculateGradient (length: 133 --> 110)\n",
      "Backward (length: 110 --> 87)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "targets = {\"aten::\": \"ManipulateTensor\", \"autograd::\": \"CalculateGradient\", \"Backward\": \"Backward\"}\n",
    "\n",
    "for key, val in total_durs.items():\n",
    "    print(key)\n",
    "    for target, alt_name in targets.items():\n",
    "        len_ori = len(val)\n",
    "        df_temp = val[val[\"name\"].str.contains(target)]\n",
    "        val.loc[len_ori] = ({\"cat\": \"cpu_op\", \"name\": alt_name, \"dur\": df_temp[\"dur\"].sum()})\n",
    "        val.drop(df_temp.index, inplace=True)\n",
    "        val.reset_index(drop=True, inplace=True)\n",
    "        print(f\"{alt_name} (length: {len_ori} --> {len(val)})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>name</th>\n",
       "      <th>dur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trace</td>\n",
       "      <td>PyTorch Profiler (0)</td>\n",
       "      <td>3502589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cpu_op</td>\n",
       "      <td>ManipulateTensor</td>\n",
       "      <td>5108633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cpu_op</td>\n",
       "      <td>CalculateGradient</td>\n",
       "      <td>3396507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cpu_op</td>\n",
       "      <td>Backward</td>\n",
       "      <td>2518651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cpu_op</td>\n",
       "      <td>c10d::allreduce_</td>\n",
       "      <td>11061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cpu_op</td>\n",
       "      <td>record_param_comms</td>\n",
       "      <td>10246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cpu_op</td>\n",
       "      <td>GeLUFunction</td>\n",
       "      <td>8231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cpu_op</td>\n",
       "      <td>torch.distributed.ddp.reducer::copy_bucket_to_grad</td>\n",
       "      <td>5956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cpu_op</td>\n",
       "      <td>detach_</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaLaunchKernel</td>\n",
       "      <td>2283745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaStreamSynchronize</td>\n",
       "      <td>681972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaMemsetAsync</td>\n",
       "      <td>208277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaMemcpyAsync</td>\n",
       "      <td>133927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaEventQuery</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaStreamWaitEvent</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaOccupancyMaxActiveBlocksPerMultiprocessor</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaDeviceSynchronize</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaEventElapsedTime</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaStreamIsCapturing</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaDeviceGetAttribute</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpu_memcpy</td>\n",
       "      <td>Memcpy DtoD (Device -&gt; Device)</td>\n",
       "      <td>39672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpu_memcpy</td>\n",
       "      <td>Memcpy HtoD (Pageable -&gt; Device)</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gpu_memcpy</td>\n",
       "      <td>Memcpy DtoH (Device -&gt; Pageable)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gpu_memset</td>\n",
       "      <td>Memset (Device)</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_128x64_tn</td>\n",
       "      <td>680468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_64x32_sliced1x4_nn</td>\n",
       "      <td>572362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void cutlass::Kernel&lt;cutlass_80_simt_sgemm_128x32_8x5_nt...</td>\n",
       "      <td>402761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void cutlass::Kernel&lt;cutlass_80_simt_sgemm_32x128_8x5_nt...</td>\n",
       "      <td>336074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_32x128_tn</td>\n",
       "      <td>219733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_128x32_nn</td>\n",
       "      <td>214912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_128x64_nn</td>\n",
       "      <td>199267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_128x128_nt</td>\n",
       "      <td>157804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ncclKernel_AllReduce_RING_LL_Sum_float(ncclDevComm*, uns...</td>\n",
       "      <td>118110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>88001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>62305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_128x32_tn</td>\n",
       "      <td>54433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_64x32_sliced1x4_nt</td>\n",
       "      <td>52242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>51626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 2, at::native::...</td>\n",
       "      <td>47035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::multi_tensor_app...</td>\n",
       "      <td>34166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>29864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>29224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::multi_tensor_app...</td>\n",
       "      <td>20705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::cunn_SoftMaxForw...</td>\n",
       "      <td>19208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::multi_tensor_app...</td>\n",
       "      <td>16106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::multi_tensor_app...</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>13237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_128x128_tn</td>\n",
       "      <td>12215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_128x128_nn</td>\n",
       "      <td>12144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::multi_tensor_app...</td>\n",
       "      <td>11561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::multi_tensor_app...</td>\n",
       "      <td>11373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::multi_tensor_app...</td>\n",
       "      <td>11247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::reduce_kernel&lt;128, 4, at::native::Reduc...</td>\n",
       "      <td>8600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::layer_norm_grad_...</td>\n",
       "      <td>6692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>5766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 2, at::native::...</td>\n",
       "      <td>4765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::vectorized_layer...</td>\n",
       "      <td>3951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void (anonymous namespace)::softmax_warp_backward&lt;float,...</td>\n",
       "      <td>2907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void (anonymous namespace)::softmax_warp_forward&lt;float, ...</td>\n",
       "      <td>2217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::nll_loss_forward...</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel&lt;...</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::nll_loss_backwar...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::indexSelectLarge...</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::compute_grad_wei...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::sum_and_scatter&lt;...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>kernel</td>\n",
       "      <td>std::enable_if&lt;!c10::is_complex&lt;long&gt;::value, void&gt;::typ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void (anonymous namespace)::elementwise_kernel_with_inde...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at_cuda_detail::cub::DeviceRadixSortExclusiveSumKer...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at_cuda_detail::cub::DeviceRadixSortHistogramKernel...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 4, at::native::...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 4, at::native::...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void thrust::cuda_cub::core::_kernel_agent&lt;thrust::cuda_...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 2, at::native::...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at_cuda_detail::cub::DeviceScanKernel&lt;at_cuda_detai...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 4, at::native::...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 4, at::native::...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::unrolled_elementwise_kernel&lt;at::native:...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::krn_partial_segm...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::krn_partials_per...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void thrust::cuda_cub::core::_kernel_agent&lt;thrust::cuda_...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void (anonymous namespace)::elementwise_kernel_with_inde...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>kernel</td>\n",
       "      <td>at::native::(anonymous namespace)::write_num_of_segments...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at_cuda_detail::cub::DeviceScanInitKernel&lt;at_cuda_d...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::compute_num_of_p...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>user_annotation</td>\n",
       "      <td>ProfilerStep#1</td>\n",
       "      <td>1751246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>user_annotation</td>\n",
       "      <td>ProfilerStep#2</td>\n",
       "      <td>1750930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>user_annotation</td>\n",
       "      <td>DistributedDataParallel.forward</td>\n",
       "      <td>54826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>user_annotation</td>\n",
       "      <td>Optimizer.step#AdamW.step</td>\n",
       "      <td>28385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>user_annotation</td>\n",
       "      <td>Optimizer.zero_grad#AdamW.zero_grad</td>\n",
       "      <td>7931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>user_annotation</td>\n",
       "      <td>nccl:all_reduce</td>\n",
       "      <td>7750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>user_annotation</td>\n",
       "      <td>enumerate(DataLoader)#_SingleProcessDataLoaderIter.__next__</td>\n",
       "      <td>4418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cat  \\\n",
       "0             Trace   \n",
       "1            cpu_op   \n",
       "2            cpu_op   \n",
       "3            cpu_op   \n",
       "4            cpu_op   \n",
       "5            cpu_op   \n",
       "6            cpu_op   \n",
       "7            cpu_op   \n",
       "8            cpu_op   \n",
       "9      cuda_runtime   \n",
       "10     cuda_runtime   \n",
       "11     cuda_runtime   \n",
       "12     cuda_runtime   \n",
       "13     cuda_runtime   \n",
       "14     cuda_runtime   \n",
       "15     cuda_runtime   \n",
       "16     cuda_runtime   \n",
       "17     cuda_runtime   \n",
       "18     cuda_runtime   \n",
       "19     cuda_runtime   \n",
       "20     cuda_runtime   \n",
       "21     cuda_runtime   \n",
       "22       gpu_memcpy   \n",
       "23       gpu_memcpy   \n",
       "24       gpu_memcpy   \n",
       "25       gpu_memset   \n",
       "26           kernel   \n",
       "27           kernel   \n",
       "28           kernel   \n",
       "29           kernel   \n",
       "30           kernel   \n",
       "31           kernel   \n",
       "32           kernel   \n",
       "33           kernel   \n",
       "34           kernel   \n",
       "35           kernel   \n",
       "36           kernel   \n",
       "37           kernel   \n",
       "38           kernel   \n",
       "39           kernel   \n",
       "40           kernel   \n",
       "41           kernel   \n",
       "42           kernel   \n",
       "43           kernel   \n",
       "44           kernel   \n",
       "45           kernel   \n",
       "46           kernel   \n",
       "47           kernel   \n",
       "48           kernel   \n",
       "49           kernel   \n",
       "50           kernel   \n",
       "51           kernel   \n",
       "52           kernel   \n",
       "53           kernel   \n",
       "54           kernel   \n",
       "55           kernel   \n",
       "56           kernel   \n",
       "57           kernel   \n",
       "58           kernel   \n",
       "59           kernel   \n",
       "60           kernel   \n",
       "61           kernel   \n",
       "62           kernel   \n",
       "63           kernel   \n",
       "64           kernel   \n",
       "65           kernel   \n",
       "66           kernel   \n",
       "67           kernel   \n",
       "68           kernel   \n",
       "69           kernel   \n",
       "70           kernel   \n",
       "71           kernel   \n",
       "72           kernel   \n",
       "73           kernel   \n",
       "74           kernel   \n",
       "75           kernel   \n",
       "76           kernel   \n",
       "77           kernel   \n",
       "78           kernel   \n",
       "79           kernel   \n",
       "80           kernel   \n",
       "81           kernel   \n",
       "82           kernel   \n",
       "83           kernel   \n",
       "84           kernel   \n",
       "85           kernel   \n",
       "86           kernel   \n",
       "87           kernel   \n",
       "88           kernel   \n",
       "89           kernel   \n",
       "90  user_annotation   \n",
       "91  user_annotation   \n",
       "92  user_annotation   \n",
       "93  user_annotation   \n",
       "94  user_annotation   \n",
       "95  user_annotation   \n",
       "96  user_annotation   \n",
       "\n",
       "                                                           name      dur  \n",
       "0                                          PyTorch Profiler (0)  3502589  \n",
       "1                                              ManipulateTensor  5108633  \n",
       "2                                             CalculateGradient  3396507  \n",
       "3                                                      Backward  2518651  \n",
       "4                                              c10d::allreduce_    11061  \n",
       "5                                            record_param_comms    10246  \n",
       "6                                                  GeLUFunction     8231  \n",
       "7            torch.distributed.ddp.reducer::copy_bucket_to_grad     5956  \n",
       "8                                                       detach_        4  \n",
       "9                                              cudaLaunchKernel  2283745  \n",
       "10                                        cudaStreamSynchronize   681972  \n",
       "11                                              cudaMemsetAsync   208277  \n",
       "12                                              cudaMemcpyAsync   133927  \n",
       "13                                               cudaEventQuery     1129  \n",
       "14                                          cudaStreamWaitEvent      942  \n",
       "15                cudaOccupancyMaxActiveBlocksPerMultiprocessor      347  \n",
       "16       cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags       62  \n",
       "17                                        cudaDeviceSynchronize       31  \n",
       "18                                         cudaEventElapsedTime       28  \n",
       "19                                        cudaStreamIsCapturing        8  \n",
       "20                                       cudaDeviceGetAttribute        4  \n",
       "21                                                      INVALID        2  \n",
       "22                               Memcpy DtoD (Device -> Device)    39672  \n",
       "23                             Memcpy HtoD (Pageable -> Device)       28  \n",
       "24                             Memcpy DtoH (Device -> Pageable)        8  \n",
       "25                                              Memset (Device)      470  \n",
       "26                                       ampere_sgemm_128x64_tn   680468  \n",
       "27                              ampere_sgemm_64x32_sliced1x4_nn   572362  \n",
       "28  void cutlass::Kernel<cutlass_80_simt_sgemm_128x32_8x5_nt...   402761  \n",
       "29  void cutlass::Kernel<cutlass_80_simt_sgemm_32x128_8x5_nt...   336074  \n",
       "30                                       ampere_sgemm_32x128_tn   219733  \n",
       "31                                       ampere_sgemm_128x32_nn   214912  \n",
       "32                                       ampere_sgemm_128x64_nn   199267  \n",
       "33                                      ampere_sgemm_128x128_nt   157804  \n",
       "34  ncclKernel_AllReduce_RING_LL_Sum_float(ncclDevComm*, uns...   118110  \n",
       "35  void at::native::vectorized_elementwise_kernel<4, at::na...    88001  \n",
       "36  void at::native::vectorized_elementwise_kernel<4, at::na...    62305  \n",
       "37                                       ampere_sgemm_128x32_tn    54433  \n",
       "38                              ampere_sgemm_64x32_sliced1x4_nt    52242  \n",
       "39  void at::native::vectorized_elementwise_kernel<4, at::na...    51626  \n",
       "40  void at::native::elementwise_kernel<128, 2, at::native::...    47035  \n",
       "41  void at::native::(anonymous namespace)::multi_tensor_app...    34166  \n",
       "42  void at::native::vectorized_elementwise_kernel<4, at::na...    29864  \n",
       "43  void at::native::vectorized_elementwise_kernel<4, at::na...    29224  \n",
       "44  void at::native::(anonymous namespace)::multi_tensor_app...    20705  \n",
       "45  void at::native::(anonymous namespace)::cunn_SoftMaxForw...    19208  \n",
       "46  void at::native::(anonymous namespace)::multi_tensor_app...    16106  \n",
       "47  void at::native::(anonymous namespace)::multi_tensor_app...    16000  \n",
       "48  void at::native::vectorized_elementwise_kernel<4, at::na...    13237  \n",
       "49                                      ampere_sgemm_128x128_tn    12215  \n",
       "50                                      ampere_sgemm_128x128_nn    12144  \n",
       "51  void at::native::(anonymous namespace)::multi_tensor_app...    11561  \n",
       "52  void at::native::(anonymous namespace)::multi_tensor_app...    11373  \n",
       "53  void at::native::(anonymous namespace)::multi_tensor_app...    11247  \n",
       "54  void at::native::reduce_kernel<128, 4, at::native::Reduc...     8600  \n",
       "55  void at::native::(anonymous namespace)::layer_norm_grad_...     6692  \n",
       "56  void at::native::vectorized_elementwise_kernel<4, at::na...     5766  \n",
       "57  void at::native::elementwise_kernel<128, 2, at::native::...     4765  \n",
       "58  void at::native::(anonymous namespace)::vectorized_layer...     3951  \n",
       "59  void (anonymous namespace)::softmax_warp_backward<float,...     2907  \n",
       "60  void (anonymous namespace)::softmax_warp_forward<float, ...     2217  \n",
       "61  void at::native::(anonymous namespace)::nll_loss_forward...      292  \n",
       "62  void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<...      221  \n",
       "63  void at::native::(anonymous namespace)::nll_loss_backwar...      149  \n",
       "64  void at::native::(anonymous namespace)::indexSelectLarge...      147  \n",
       "65  void at::native::(anonymous namespace)::compute_grad_wei...      118  \n",
       "66  void at::native::(anonymous namespace)::sum_and_scatter<...       82  \n",
       "67  std::enable_if<!c10::is_complex<long>::value, void>::typ...       23  \n",
       "68  void (anonymous namespace)::elementwise_kernel_with_inde...       19  \n",
       "69  void at_cuda_detail::cub::DeviceRadixSortExclusiveSumKer...       19  \n",
       "70  void at::native::vectorized_elementwise_kernel<4, at::na...       18  \n",
       "71  void at_cuda_detail::cub::DeviceRadixSortHistogramKernel...       16  \n",
       "72  void at::native::elementwise_kernel<128, 4, at::native::...       14  \n",
       "73  void at::native::elementwise_kernel<128, 4, at::native::...       14  \n",
       "74  void thrust::cuda_cub::core::_kernel_agent<thrust::cuda_...       14  \n",
       "75  void at::native::elementwise_kernel<128, 2, at::native::...       12  \n",
       "76  void at_cuda_detail::cub::DeviceScanKernel<at_cuda_detai...       12  \n",
       "77  void at::native::elementwise_kernel<128, 4, at::native::...       10  \n",
       "78  void at::native::elementwise_kernel<128, 4, at::native::...       10  \n",
       "79  void at::native::unrolled_elementwise_kernel<at::native:...       10  \n",
       "80  void at::native::(anonymous namespace)::krn_partial_segm...       10  \n",
       "81  void at::native::vectorized_elementwise_kernel<4, at::na...        8  \n",
       "82  void at::native::vectorized_elementwise_kernel<4, at::na...        8  \n",
       "83  void at::native::(anonymous namespace)::krn_partials_per...        8  \n",
       "84  void thrust::cuda_cub::core::_kernel_agent<thrust::cuda_...        7  \n",
       "85  void (anonymous namespace)::elementwise_kernel_with_inde...        6  \n",
       "86  void at::native::vectorized_elementwise_kernel<4, at::na...        6  \n",
       "87  at::native::(anonymous namespace)::write_num_of_segments...        6  \n",
       "88  void at_cuda_detail::cub::DeviceScanInitKernel<at_cuda_d...        6  \n",
       "89  void at::native::(anonymous namespace)::compute_num_of_p...        6  \n",
       "90                                               ProfilerStep#1  1751246  \n",
       "91                                               ProfilerStep#2  1750930  \n",
       "92                              DistributedDataParallel.forward    54826  \n",
       "93                                    Optimizer.step#AdamW.step    28385  \n",
       "94                          Optimizer.zero_grad#AdamW.zero_grad     7931  \n",
       "95                                              nccl:all_reduce     7750  \n",
       "96  enumerate(DataLoader)#_SingleProcessDataLoaderIter.__next__     4418  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>name</th>\n",
       "      <th>dur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trace</td>\n",
       "      <td>PyTorch Profiler (0)</td>\n",
       "      <td>3443483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cpu_op</td>\n",
       "      <td>ManipulateTensor</td>\n",
       "      <td>4957827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cpu_op</td>\n",
       "      <td>CalculateGradient</td>\n",
       "      <td>3717495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cpu_op</td>\n",
       "      <td>Backward</td>\n",
       "      <td>2636824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cpu_op</td>\n",
       "      <td>GeLUFunction</td>\n",
       "      <td>8134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cpu_op</td>\n",
       "      <td>detach_</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaLaunchKernel</td>\n",
       "      <td>2251305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaStreamSynchronize</td>\n",
       "      <td>772730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaMemcpyAsync</td>\n",
       "      <td>204751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaMemsetAsync</td>\n",
       "      <td>51274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaOccupancyMaxActiveBlocksPerMultiprocessor</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaDeviceSynchronize</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaStreamIsCapturing</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cuda_runtime</td>\n",
       "      <td>cudaDeviceGetAttribute</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpu_memcpy</td>\n",
       "      <td>Memcpy DtoD (Device -&gt; Device)</td>\n",
       "      <td>14442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpu_memcpy</td>\n",
       "      <td>Memcpy HtoD (Pageable -&gt; Device)</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpu_memcpy</td>\n",
       "      <td>Memcpy DtoH (Device -&gt; Pageable)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpu_memset</td>\n",
       "      <td>Memset (Device)</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_128x64_tn</td>\n",
       "      <td>680280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_64x32_sliced1x4_nn</td>\n",
       "      <td>573323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void cutlass::Kernel&lt;cutlass_80_simt_sgemm_128x32_8x5_nt...</td>\n",
       "      <td>402945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void cutlass::Kernel&lt;cutlass_80_simt_sgemm_32x128_8x5_nt...</td>\n",
       "      <td>336226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_32x128_tn</td>\n",
       "      <td>219874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_128x32_nn</td>\n",
       "      <td>213991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_128x64_nn</td>\n",
       "      <td>199707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_128x128_nt</td>\n",
       "      <td>157915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>84305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_128x32_tn</td>\n",
       "      <td>54446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_64x32_sliced1x4_nt</td>\n",
       "      <td>52239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>48552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>47651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 2, at::native::...</td>\n",
       "      <td>46925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::multi_tensor_app...</td>\n",
       "      <td>34174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>29101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>28064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::multi_tensor_app...</td>\n",
       "      <td>20604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::cunn_SoftMaxForw...</td>\n",
       "      <td>19195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::multi_tensor_app...</td>\n",
       "      <td>16113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::multi_tensor_app...</td>\n",
       "      <td>15939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_128x128_tn</td>\n",
       "      <td>12201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>kernel</td>\n",
       "      <td>ampere_sgemm_128x128_nn</td>\n",
       "      <td>12139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::multi_tensor_app...</td>\n",
       "      <td>11583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::multi_tensor_app...</td>\n",
       "      <td>11359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>11338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::multi_tensor_app...</td>\n",
       "      <td>11279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::reduce_kernel&lt;128, 4, at::native::Reduc...</td>\n",
       "      <td>8532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::layer_norm_grad_...</td>\n",
       "      <td>6034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>5799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 2, at::native::...</td>\n",
       "      <td>4764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::vectorized_layer...</td>\n",
       "      <td>3948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void (anonymous namespace)::softmax_warp_backward&lt;float,...</td>\n",
       "      <td>2919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void (anonymous namespace)::softmax_warp_forward&lt;float, ...</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::nll_loss_forward...</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel&lt;...</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::nll_loss_backwar...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::indexSelectLarge...</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::compute_grad_wei...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::sum_and_scatter&lt;...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>kernel</td>\n",
       "      <td>std::enable_if&lt;!c10::is_complex&lt;long&gt;::value, void&gt;::typ...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 4, at::native::...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 4, at::native::...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at_cuda_detail::cub::DeviceRadixSortHistogramKernel...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void thrust::cuda_cub::core::_kernel_agent&lt;thrust::cuda_...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void (anonymous namespace)::elementwise_kernel_with_inde...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 2, at::native::...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at_cuda_detail::cub::DeviceScanKernel&lt;at_cuda_detai...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 4, at::native::...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::elementwise_kernel&lt;128, 4, at::native::...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::unrolled_elementwise_kernel&lt;at::native:...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::krn_partial_segm...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::vectorized_elementwise_kernel&lt;4, at::na...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at_cuda_detail::cub::DeviceRadixSortExclusiveSumKer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void thrust::cuda_cub::core::_kernel_agent&lt;thrust::cuda_...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::krn_partials_per...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void (anonymous namespace)::elementwise_kernel_with_inde...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>kernel</td>\n",
       "      <td>at::native::(anonymous namespace)::write_num_of_segments...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at_cuda_detail::cub::DeviceScanInitKernel&lt;at_cuda_d...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>kernel</td>\n",
       "      <td>void at::native::(anonymous namespace)::compute_num_of_p...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>user_annotation</td>\n",
       "      <td>ProfilerStep#2</td>\n",
       "      <td>1722104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>user_annotation</td>\n",
       "      <td>ProfilerStep#1</td>\n",
       "      <td>1721066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>user_annotation</td>\n",
       "      <td>Optimizer.step#AdamW.step</td>\n",
       "      <td>28718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>user_annotation</td>\n",
       "      <td>Optimizer.zero_grad#AdamW.zero_grad</td>\n",
       "      <td>7921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>user_annotation</td>\n",
       "      <td>enumerate(DataLoader)#_SingleProcessDataLoaderIter.__next__</td>\n",
       "      <td>3904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cat  \\\n",
       "0             Trace   \n",
       "1            cpu_op   \n",
       "2            cpu_op   \n",
       "3            cpu_op   \n",
       "4            cpu_op   \n",
       "5            cpu_op   \n",
       "6      cuda_runtime   \n",
       "7      cuda_runtime   \n",
       "8      cuda_runtime   \n",
       "9      cuda_runtime   \n",
       "10     cuda_runtime   \n",
       "11     cuda_runtime   \n",
       "12     cuda_runtime   \n",
       "13     cuda_runtime   \n",
       "14     cuda_runtime   \n",
       "15       gpu_memcpy   \n",
       "16       gpu_memcpy   \n",
       "17       gpu_memcpy   \n",
       "18       gpu_memset   \n",
       "19           kernel   \n",
       "20           kernel   \n",
       "21           kernel   \n",
       "22           kernel   \n",
       "23           kernel   \n",
       "24           kernel   \n",
       "25           kernel   \n",
       "26           kernel   \n",
       "27           kernel   \n",
       "28           kernel   \n",
       "29           kernel   \n",
       "30           kernel   \n",
       "31           kernel   \n",
       "32           kernel   \n",
       "33           kernel   \n",
       "34           kernel   \n",
       "35           kernel   \n",
       "36           kernel   \n",
       "37           kernel   \n",
       "38           kernel   \n",
       "39           kernel   \n",
       "40           kernel   \n",
       "41           kernel   \n",
       "42           kernel   \n",
       "43           kernel   \n",
       "44           kernel   \n",
       "45           kernel   \n",
       "46           kernel   \n",
       "47           kernel   \n",
       "48           kernel   \n",
       "49           kernel   \n",
       "50           kernel   \n",
       "51           kernel   \n",
       "52           kernel   \n",
       "53           kernel   \n",
       "54           kernel   \n",
       "55           kernel   \n",
       "56           kernel   \n",
       "57           kernel   \n",
       "58           kernel   \n",
       "59           kernel   \n",
       "60           kernel   \n",
       "61           kernel   \n",
       "62           kernel   \n",
       "63           kernel   \n",
       "64           kernel   \n",
       "65           kernel   \n",
       "66           kernel   \n",
       "67           kernel   \n",
       "68           kernel   \n",
       "69           kernel   \n",
       "70           kernel   \n",
       "71           kernel   \n",
       "72           kernel   \n",
       "73           kernel   \n",
       "74           kernel   \n",
       "75           kernel   \n",
       "76           kernel   \n",
       "77           kernel   \n",
       "78           kernel   \n",
       "79           kernel   \n",
       "80           kernel   \n",
       "81           kernel   \n",
       "82  user_annotation   \n",
       "83  user_annotation   \n",
       "84  user_annotation   \n",
       "85  user_annotation   \n",
       "86  user_annotation   \n",
       "\n",
       "                                                           name      dur  \n",
       "0                                          PyTorch Profiler (0)  3443483  \n",
       "1                                              ManipulateTensor  4957827  \n",
       "2                                             CalculateGradient  3717495  \n",
       "3                                                      Backward  2636824  \n",
       "4                                                  GeLUFunction     8134  \n",
       "5                                                       detach_        5  \n",
       "6                                              cudaLaunchKernel  2251305  \n",
       "7                                         cudaStreamSynchronize   772730  \n",
       "8                                               cudaMemcpyAsync   204751  \n",
       "9                                               cudaMemsetAsync    51274  \n",
       "10                cudaOccupancyMaxActiveBlocksPerMultiprocessor      348  \n",
       "11       cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags       51  \n",
       "12                                        cudaDeviceSynchronize       10  \n",
       "13                                        cudaStreamIsCapturing        7  \n",
       "14                                       cudaDeviceGetAttribute        6  \n",
       "15                               Memcpy DtoD (Device -> Device)    14442  \n",
       "16                             Memcpy HtoD (Pageable -> Device)       30  \n",
       "17                             Memcpy DtoH (Device -> Pageable)        8  \n",
       "18                                              Memset (Device)      426  \n",
       "19                                       ampere_sgemm_128x64_tn   680280  \n",
       "20                              ampere_sgemm_64x32_sliced1x4_nn   573323  \n",
       "21  void cutlass::Kernel<cutlass_80_simt_sgemm_128x32_8x5_nt...   402945  \n",
       "22  void cutlass::Kernel<cutlass_80_simt_sgemm_32x128_8x5_nt...   336226  \n",
       "23                                       ampere_sgemm_32x128_tn   219874  \n",
       "24                                       ampere_sgemm_128x32_nn   213991  \n",
       "25                                       ampere_sgemm_128x64_nn   199707  \n",
       "26                                      ampere_sgemm_128x128_nt   157915  \n",
       "27  void at::native::vectorized_elementwise_kernel<4, at::na...    84305  \n",
       "28                                       ampere_sgemm_128x32_tn    54446  \n",
       "29                              ampere_sgemm_64x32_sliced1x4_nt    52239  \n",
       "30  void at::native::vectorized_elementwise_kernel<4, at::na...    48552  \n",
       "31  void at::native::vectorized_elementwise_kernel<4, at::na...    47651  \n",
       "32  void at::native::elementwise_kernel<128, 2, at::native::...    46925  \n",
       "33  void at::native::(anonymous namespace)::multi_tensor_app...    34174  \n",
       "34  void at::native::vectorized_elementwise_kernel<4, at::na...    29101  \n",
       "35  void at::native::vectorized_elementwise_kernel<4, at::na...    28064  \n",
       "36  void at::native::(anonymous namespace)::multi_tensor_app...    20604  \n",
       "37  void at::native::(anonymous namespace)::cunn_SoftMaxForw...    19195  \n",
       "38  void at::native::(anonymous namespace)::multi_tensor_app...    16113  \n",
       "39  void at::native::(anonymous namespace)::multi_tensor_app...    15939  \n",
       "40                                      ampere_sgemm_128x128_tn    12201  \n",
       "41                                      ampere_sgemm_128x128_nn    12139  \n",
       "42  void at::native::(anonymous namespace)::multi_tensor_app...    11583  \n",
       "43  void at::native::(anonymous namespace)::multi_tensor_app...    11359  \n",
       "44  void at::native::vectorized_elementwise_kernel<4, at::na...    11338  \n",
       "45  void at::native::(anonymous namespace)::multi_tensor_app...    11279  \n",
       "46  void at::native::reduce_kernel<128, 4, at::native::Reduc...     8532  \n",
       "47  void at::native::(anonymous namespace)::layer_norm_grad_...     6034  \n",
       "48  void at::native::vectorized_elementwise_kernel<4, at::na...     5799  \n",
       "49  void at::native::elementwise_kernel<128, 2, at::native::...     4764  \n",
       "50  void at::native::(anonymous namespace)::vectorized_layer...     3948  \n",
       "51  void (anonymous namespace)::softmax_warp_backward<float,...     2919  \n",
       "52  void (anonymous namespace)::softmax_warp_forward<float, ...     2222  \n",
       "53  void at::native::(anonymous namespace)::nll_loss_forward...      290  \n",
       "54  void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<...      173  \n",
       "55  void at::native::(anonymous namespace)::nll_loss_backwar...      149  \n",
       "56  void at::native::(anonymous namespace)::indexSelectLarge...      148  \n",
       "57  void at::native::(anonymous namespace)::compute_grad_wei...      118  \n",
       "58  void at::native::(anonymous namespace)::sum_and_scatter<...       83  \n",
       "59  std::enable_if<!c10::is_complex<long>::value, void>::typ...       24  \n",
       "60  void at::native::vectorized_elementwise_kernel<4, at::na...       18  \n",
       "61  void at::native::elementwise_kernel<128, 4, at::native::...       14  \n",
       "62  void at::native::elementwise_kernel<128, 4, at::native::...       14  \n",
       "63  void at_cuda_detail::cub::DeviceRadixSortHistogramKernel...       13  \n",
       "64  void thrust::cuda_cub::core::_kernel_agent<thrust::cuda_...       13  \n",
       "65  void (anonymous namespace)::elementwise_kernel_with_inde...       12  \n",
       "66  void at::native::elementwise_kernel<128, 2, at::native::...       12  \n",
       "67  void at_cuda_detail::cub::DeviceScanKernel<at_cuda_detai...       12  \n",
       "68  void at::native::elementwise_kernel<128, 4, at::native::...       10  \n",
       "69  void at::native::elementwise_kernel<128, 4, at::native::...       10  \n",
       "70  void at::native::unrolled_elementwise_kernel<at::native:...       10  \n",
       "71  void at::native::(anonymous namespace)::krn_partial_segm...       10  \n",
       "72  void at::native::vectorized_elementwise_kernel<4, at::na...        8  \n",
       "73  void at::native::vectorized_elementwise_kernel<4, at::na...        8  \n",
       "74  void at::native::vectorized_elementwise_kernel<4, at::na...        8  \n",
       "75  void at_cuda_detail::cub::DeviceRadixSortExclusiveSumKer...        8  \n",
       "76  void thrust::cuda_cub::core::_kernel_agent<thrust::cuda_...        8  \n",
       "77  void at::native::(anonymous namespace)::krn_partials_per...        8  \n",
       "78  void (anonymous namespace)::elementwise_kernel_with_inde...        6  \n",
       "79  at::native::(anonymous namespace)::write_num_of_segments...        6  \n",
       "80  void at_cuda_detail::cub::DeviceScanInitKernel<at_cuda_d...        6  \n",
       "81  void at::native::(anonymous namespace)::compute_num_of_p...        6  \n",
       "82                                               ProfilerStep#2  1722104  \n",
       "83                                               ProfilerStep#1  1721066  \n",
       "84                                    Optimizer.step#AdamW.step    28718  \n",
       "85                          Optimizer.zero_grad#AdamW.zero_grad     7921  \n",
       "86  enumerate(DataLoader)#_SingleProcessDataLoaderIter.__next__     3904  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_rows\", None)  # Display all rows\n",
    "pd.set_option(\"display.max_columns\", None)  # Display all columns\n",
    "pd.set_option(\"display.max_colwidth\", 60)\n",
    "\n",
    "for idx, val in enumerate(total_durs.values()):\n",
    "    val = val.sort_values(by=[\"cat\", \"dur\"], ascending=[True, False])\n",
    "    val.reset_index(drop=True, inplace=True)\n",
    "    trace = traces[idx]\n",
    "    val.to_csv(f\"{trace[:trace.rfind('/')]}/trace.csv\")\n",
    "    display(val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
