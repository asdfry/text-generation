version: "3.6"

services:

  api-1:
    image: asdfry/text-generation:inference-${version}
    build:
      context: .
      dockerfile: Dockerfile
    command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
    volumes:
      - /gpfs/user/jsh:/root/pretrained-models:ro
    ports:
      - 1041:8000
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ["0"]
            capabilities: [gpu]

  api-2:
    image: asdfry/text-generation:inference-${version}
    build:
      context: .
      dockerfile: Dockerfile
    command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
    volumes:
      - /gpfs/user/jsh:/root/pretrained-models:ro
    ports:
      - 1042:8000
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ["1"]
            capabilities: [gpu]

  api-3:
    image: asdfry/text-generation:inference-${version}
    build:
      context: .
      dockerfile: Dockerfile
    command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
    volumes:
      - /gpfs/user/jsh:/root/pretrained-models:ro
    ports:
      - 1043:8000
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ["2"]
            capabilities: [gpu]

  api-4:
    image: asdfry/text-generation:inference-${version}
    build:
      context: .
      dockerfile: Dockerfile
    command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
    volumes:
      - /gpfs/user/jsh:/root/pretrained-models:ro
    ports:
      - 1044:8000
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ["3"]
            capabilities: [gpu]

  api-5:
    image: asdfry/text-generation:inference-${version}
    build:
      context: .
      dockerfile: Dockerfile
    command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
    volumes:
      - /gpfs/user/jsh:/root/pretrained-models:ro
    ports:
      - 1045:8000
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ["4"]
            capabilities: [gpu]

  api-6:
    image: asdfry/text-generation:inference-${version}
    build:
      context: .
      dockerfile: Dockerfile
    command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
    volumes:
      - /gpfs/user/jsh:/root/pretrained-models:ro
    ports:
      - 1046:8000
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ["5"]
            capabilities: [gpu]

  api-7:
    image: asdfry/text-generation:inference-${version}
    build:
      context: .
      dockerfile: Dockerfile
    command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
    volumes:
      - /gpfs/user/jsh:/root/pretrained-models:ro
    ports:
      - 1047:8000
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ["6"]
            capabilities: [gpu]

  api-8:
    image: asdfry/text-generation:inference-${version}
    build:
      context: .
      dockerfile: Dockerfile
    command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
    volumes:
      - /gpfs/user/jsh:/root/pretrained-models:ro
    ports:
      - 1048:8000
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            device_ids: ["7"]
            capabilities: [gpu]
