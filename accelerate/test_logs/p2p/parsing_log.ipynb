{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_time = re.compile(r\"\\[epoch (\\d)\\] elapsed time\\: (\\d+\\.\\d+) sec\")\n",
    "pt_p2p = re.compile(r\"p2p_([a-z]+)\")\n",
    "pt_node = re.compile(r\"node(\\d+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = sorted(glob(\"./**/**/torch.log\"))\n",
    "rows = []\n",
    "\n",
    "for log in logs:\n",
    "    with open(log, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    time_per_epoch = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "    for line in lines:\n",
    "        sh_time = pt_time.search(line)\n",
    "        if sh_time:\n",
    "            time_per_epoch[int(sh_time.group(1))] = float(sh_time.group(2))\n",
    "\n",
    "    p2p = pt_p2p.search(log).group(1)\n",
    "    if p2p == \"enable\":\n",
    "        p2p = \"on\"\n",
    "    else:\n",
    "        p2p = \"off\"\n",
    "\n",
    "    node_num = int(pt_node.search(log).group(1))\n",
    "    if node_num == 4:\n",
    "        gpus = \"A100 * 4\"\n",
    "    if node_num == 5:\n",
    "        gpus = \"H100 * 4\"\n",
    "    elif node_num == 7:\n",
    "        gpus = \"L40 * 4\"\n",
    "    elif node_num == 8:\n",
    "        gpus = \"A40 * 4\"\n",
    "    elif node_num == 9:\n",
    "        gpus = \"L4 * 4\"\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"model\": log.split(\"/\")[1],\n",
    "            \"gpus\": gpus,\n",
    "            \"nvlink\": p2p,\n",
    "            \"epoch_1\": round(time_per_epoch[1], 2),\n",
    "            \"epoch_2\": round(time_per_epoch[2], 2),\n",
    "            \"epoch_3\": round(time_per_epoch[3], 2),\n",
    "            \"epoch_4\": round(time_per_epoch[4], 2),\n",
    "            \"epoch_5\": round(time_per_epoch[5], 2),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>gpus</th>\n",
       "      <th>nvlink</th>\n",
       "      <th>epoch_1</th>\n",
       "      <th>epoch_2</th>\n",
       "      <th>epoch_3</th>\n",
       "      <th>epoch_4</th>\n",
       "      <th>epoch_5</th>\n",
       "      <th>mean</th>\n",
       "      <th>standard_deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>A100 * 4</td>\n",
       "      <td>off</td>\n",
       "      <td>404.01</td>\n",
       "      <td>390.25</td>\n",
       "      <td>388.76</td>\n",
       "      <td>389.36</td>\n",
       "      <td>389.49</td>\n",
       "      <td>392.374</td>\n",
       "      <td>6.526303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>A100 * 4</td>\n",
       "      <td>on</td>\n",
       "      <td>44.63</td>\n",
       "      <td>29.40</td>\n",
       "      <td>29.41</td>\n",
       "      <td>29.43</td>\n",
       "      <td>29.38</td>\n",
       "      <td>32.450</td>\n",
       "      <td>6.808851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>H100 * 4</td>\n",
       "      <td>off</td>\n",
       "      <td>87.06</td>\n",
       "      <td>72.08</td>\n",
       "      <td>72.06</td>\n",
       "      <td>72.07</td>\n",
       "      <td>72.06</td>\n",
       "      <td>75.066</td>\n",
       "      <td>6.704855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>H100 * 4</td>\n",
       "      <td>on</td>\n",
       "      <td>28.47</td>\n",
       "      <td>13.50</td>\n",
       "      <td>13.51</td>\n",
       "      <td>13.72</td>\n",
       "      <td>13.63</td>\n",
       "      <td>16.566</td>\n",
       "      <td>6.655158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Llama-2-13b-chat-hf</td>\n",
       "      <td>A100 * 4</td>\n",
       "      <td>off</td>\n",
       "      <td>1475.53</td>\n",
       "      <td>1451.25</td>\n",
       "      <td>1451.08</td>\n",
       "      <td>1451.26</td>\n",
       "      <td>1451.62</td>\n",
       "      <td>1456.148</td>\n",
       "      <td>10.836654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Llama-2-13b-chat-hf</td>\n",
       "      <td>A100 * 4</td>\n",
       "      <td>on</td>\n",
       "      <td>165.55</td>\n",
       "      <td>150.96</td>\n",
       "      <td>143.52</td>\n",
       "      <td>155.61</td>\n",
       "      <td>152.53</td>\n",
       "      <td>153.634</td>\n",
       "      <td>8.008710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-2-13b-chat-hf</td>\n",
       "      <td>H100 * 4</td>\n",
       "      <td>off</td>\n",
       "      <td>288.35</td>\n",
       "      <td>271.07</td>\n",
       "      <td>271.91</td>\n",
       "      <td>272.22</td>\n",
       "      <td>272.00</td>\n",
       "      <td>275.110</td>\n",
       "      <td>7.414233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Llama-2-13b-chat-hf</td>\n",
       "      <td>H100 * 4</td>\n",
       "      <td>on</td>\n",
       "      <td>49.65</td>\n",
       "      <td>31.10</td>\n",
       "      <td>31.07</td>\n",
       "      <td>30.97</td>\n",
       "      <td>31.05</td>\n",
       "      <td>34.768</td>\n",
       "      <td>8.319430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model      gpus nvlink  epoch_1  epoch_2  epoch_3  epoch_4  \\\n",
       "0   Llama-2-7b-chat-hf  A100 * 4    off   404.01   390.25   388.76   389.36   \n",
       "1   Llama-2-7b-chat-hf  A100 * 4     on    44.63    29.40    29.41    29.43   \n",
       "2   Llama-2-7b-chat-hf  H100 * 4    off    87.06    72.08    72.06    72.07   \n",
       "3   Llama-2-7b-chat-hf  H100 * 4     on    28.47    13.50    13.51    13.72   \n",
       "4  Llama-2-13b-chat-hf  A100 * 4    off  1475.53  1451.25  1451.08  1451.26   \n",
       "5  Llama-2-13b-chat-hf  A100 * 4     on   165.55   150.96   143.52   155.61   \n",
       "6  Llama-2-13b-chat-hf  H100 * 4    off   288.35   271.07   271.91   272.22   \n",
       "7  Llama-2-13b-chat-hf  H100 * 4     on    49.65    31.10    31.07    30.97   \n",
       "\n",
       "   epoch_5      mean  standard_deviation  \n",
       "0   389.49   392.374            6.526303  \n",
       "1    29.38    32.450            6.808851  \n",
       "2    72.06    75.066            6.704855  \n",
       "3    13.63    16.566            6.655158  \n",
       "4  1451.62  1456.148           10.836654  \n",
       "5   152.53   153.634            8.008710  \n",
       "6   272.00   275.110            7.414233  \n",
       "7    31.05    34.768            8.319430  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(rows)\n",
    "df.sort_values(by=[\"model\", \"gpus\"], ascending=[False, True], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df[\"mean\"] = df.iloc[:, [3, 4, 5, 6, 7]].mean(axis=1)\n",
    "df[\"standard_deviation\"] = df.iloc[:, [3, 4, 5, 6, 7]].std(axis=1)\n",
    "df.to_csv(\"data_nvlink.csv\", index=False)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
